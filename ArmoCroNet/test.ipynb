{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mirco\\Desktop\\CV_pw\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import YooxDatasetHistogram, get_norm_hist\n",
    "from model_encoder import ColorAutoencoder\n",
    "\n",
    "from utils import save_checkpoint, load_checkpoint, save_some_examples\n",
    "import config\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mirco\\Desktop\\CV_pw\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[205., 205., 205.],\n",
       "         [205., 205., 205.],\n",
       "         [205., 205., 205.],\n",
       "         ...,\n",
       "         [215., 215., 215.],\n",
       "         [214., 214., 214.],\n",
       "         [214., 214., 214.]],\n",
       "\n",
       "        [[205., 205., 205.],\n",
       "         [205., 205., 205.],\n",
       "         [205., 205., 205.],\n",
       "         ...,\n",
       "         [215., 215., 215.],\n",
       "         [215., 215., 215.],\n",
       "         [214., 214., 214.]],\n",
       "\n",
       "        [[205., 205., 205.],\n",
       "         [205., 205., 205.],\n",
       "         [205., 205., 205.],\n",
       "         ...,\n",
       "         [215., 215., 215.],\n",
       "         [214., 214., 214.],\n",
       "         [214., 214., 214.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[227., 227., 227.],\n",
       "         [227., 227., 227.],\n",
       "         [227., 227., 227.],\n",
       "         ...,\n",
       "         [235., 235., 235.],\n",
       "         [235., 235., 235.],\n",
       "         [234., 234., 234.]],\n",
       "\n",
       "        [[227., 227., 227.],\n",
       "         [227., 227., 227.],\n",
       "         [227., 227., 227.],\n",
       "         ...,\n",
       "         [235., 235., 235.],\n",
       "         [235., 235., 235.],\n",
       "         [235., 235., 235.]],\n",
       "\n",
       "        [[227., 227., 227.],\n",
       "         [227., 227., 227.],\n",
       "         [227., 227., 227.],\n",
       "         ...,\n",
       "         [235., 235., 235.],\n",
       "         [235., 235., 235.],\n",
       "         [235., 235., 235.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from webbrowser import get\n",
    "\n",
    "train_dataset = YooxDatasetHistogram(True)\n",
    "train_dataset[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palette(img):\n",
    "    arr = np.asarray(img)\n",
    "    palette, index = np.unique(asvoid(arr).ravel(), return_inverse=True)\n",
    "    palette = palette.view(arr.dtype).reshape(-1, arr.shape[-1])\n",
    "    count = np.bincount(index)\n",
    "    order = np.argsort(count)\n",
    "    return palette[order[::-1]]\n",
    "\n",
    "def asvoid(arr):\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    return arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))\n",
    "\n",
    "def hsv(arr, j):\n",
    "    return matplotlib.colors.rgb_to_hsv(arr)[j]\n",
    "\n",
    "def pantone(img):\n",
    "    C = palette(img)#[:50]\n",
    "    P = None\n",
    "    n = 0\n",
    "    for c in C:\n",
    "        if P is None:\n",
    "            P = np.array(c[None,:])\n",
    "        else:\n",
    "            for d in P:\n",
    "                if ((c-d)**2).sum() > 50:\n",
    "                    P = np.concatenate([P,c[None,:]],axis=0)\n",
    "                    n += 1\n",
    "                    if n > 50:\n",
    "                        break\n",
    "\n",
    "    C = P\n",
    "    N_COLS = 5\n",
    "    model = KMeans(N_COLS)\n",
    "    model.fit(C)\n",
    "    C = model.cluster_centers_.astype(np.uint8)\n",
    "    P = np.zeros((200,N_COLS*100,3)).astype(np.uint8)\n",
    "    #for j in range(3):\n",
    "    j = 2\n",
    "    for c in range(N_COLS):\n",
    "        for d in range(N_COLS):\n",
    "            #if hsv(C[c], j) > hsv(C[d], j):\n",
    "            if hsv(C[c], j) > hsv(C[d], j):\n",
    "                tmp = C[c].copy()\n",
    "                C[c] = C[d].copy()\n",
    "                C[d] = tmp.copy()\n",
    "\n",
    "    for i, c in enumerate(C):\n",
    "        #P[100*j:100*(1+j),100*i:100*(1+i),:] = c\n",
    "        P[:,100*i:100*(1+i),:] = c\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"dataset/upper_body/images/denim_denim-shirts/12141279ui_0_r.jpg\")\n",
    "img = cv2.imread(\"dataset/upper_body/images/knitwear_track-tops/46614975wd_0_d.jpg\")\n",
    "img = cv2.imread(\"dataset/upper_body/images/knitwear_track-tops/46662850ev_0_d.jpg\")\n",
    "C = pantone(img)\n",
    "cv2.imshow(\"1\",C)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "torch.Size([3, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.9364, 0.6042, 0.3480, 1.3593]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = ColorAutoencoder(in_channels=3, levels=8).to(config.DEVICE)\n",
    "opt_gen = optim.Adam(enc.parameters(), lr=config.GEN_LEARNING_RATE, betas=(0.5, 0.999))\n",
    "load_checkpoint(config.CHECKPOINT_GEN, enc, opt_gen, config.GEN_LEARNING_RATE)\n",
    "\n",
    "x = torch.tensor(img.transpose(2,0,1)).float()\n",
    "x = get_norm_hist(x)\n",
    "enc = enc.eval()\n",
    "print(x.shape)\n",
    "enc(x.unsqueeze(0), vec_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        # num_workers=config.NUM_WORKERS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 64/1520 [00:13<04:57,  4.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mirco\\Desktop\\CV_pw\\ArmoCroNet\\test.ipynb Cella 9\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mirco/Desktop/CV_pw/ArmoCroNet/test.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m enc\u001b[39m.\u001b[39meval()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mirco/Desktop/CV_pw/ArmoCroNet/test.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mirco/Desktop/CV_pw/ArmoCroNet/test.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y, z \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mirco/Desktop/CV_pw/ArmoCroNet/test.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     res \u001b[39m=\u001b[39m enc(x, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mirco/Desktop/CV_pw/ArmoCroNet/test.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m all_vec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mirco\\Desktop\\CV_pw\\venv\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mirco\\Desktop\\CV_pw\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Mirco\\Desktop\\CV_pw\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Mirco\\Desktop\\CV_pw\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Mirco\\Desktop\\CV_pw\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Mirco\\Desktop\\CV_pw\\ArmoCroNet\\dataset.py:44\u001b[0m, in \u001b[0;36mYooxDatasetHistogram.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__getmultipleitem__(idx)\n\u001b[0;32m     43\u001b[0m path0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39miloc[idx][\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 44\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdataset/\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath0\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, cv2\u001b[39m.\u001b[39;49mIMREAD_COLOR)\n\u001b[0;32m     45\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m192\u001b[39m,\u001b[39m256\u001b[39m))\n\u001b[0;32m     47\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(img)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_vec = None\n",
    "enc.eval()\n",
    "i = 0\n",
    "for x, y, z in tqdm(train_loader):\n",
    "    res = enc(x, True)\n",
    "    if all_vec is None:\n",
    "        all_vec = res\n",
    "    else:\n",
    "        all_vec = torch.concat([all_vec, res], 0)\n",
    "        i += 1\n",
    "        if i > 50:\n",
    "            pass#break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campione = 8754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = all_vec[None,:,:] - all_vec[campione,None,:]\n",
    "diff = diff**2\n",
    "diff = diff.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    i = diff.flatten().argsort()[j+1].item()\n",
    "    p1 = pantone(train_dataset[campione][2])\n",
    "    p2 = pantone(train_dataset[i][2])\n",
    "\n",
    "    cv2.imshow(\"1\",p1)\n",
    "    cv2.imshow(\"2\",p2)\n",
    "    cv2.imshow(\"1v\",train_dataset[campione][2].numpy()/255)\n",
    "    cv2.imshow(\"2v\",train_dataset[i][2].numpy()/255)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15ce8c5ab5f6ecfdc053f441697a5123a305bcbae066728b1d823115abe8612e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
