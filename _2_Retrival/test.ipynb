{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mirco\\Desktop\\CV_pw\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from _2_Retrival.dataset import YooxDatasetSkinHistogram, YooxDatasetDressHistogram, get_multi_level_hist\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = YooxDatasetDressHistogram()\n",
    "train_dataset = YooxDatasetSkinHistogram()\n",
    "train_dataset[0][1].shape\n",
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palette(img):\n",
    "    arr = np.asarray(img)\n",
    "    palette, index = np.unique(asvoid(arr).ravel(), return_inverse=True)\n",
    "    palette = palette.view(arr.dtype).reshape(-1, arr.shape[-1])\n",
    "    count = np.bincount(index)\n",
    "    order = np.argsort(count)\n",
    "    return palette[order[::-1]]\n",
    "\n",
    "def asvoid(arr):\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    return arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))\n",
    "\n",
    "def hsv(arr, j):\n",
    "    return matplotlib.colors.rgb_to_hsv(arr)[j]\n",
    "\n",
    "def pantone(img):\n",
    "    C = palette(img)#[:50]\n",
    "    P = None\n",
    "    n = 0\n",
    "    for c in C:\n",
    "        if P is None:\n",
    "            P = np.array(c[None,:])\n",
    "        else:\n",
    "            for d in P:\n",
    "                if ((c-d)**2).sum() > 50:\n",
    "                    P = np.concatenate([P,c[None,:]],axis=0)\n",
    "                    n += 1\n",
    "                    if n > 50:\n",
    "                        break\n",
    "\n",
    "    C = P\n",
    "    N_COLS = 5\n",
    "    model = KMeans(N_COLS)\n",
    "    model.fit(C)\n",
    "    C = model.cluster_centers_.astype(np.uint8)\n",
    "    P = np.zeros((200,N_COLS*100,3)).astype(np.uint8)\n",
    "    #for j in range(3):\n",
    "    j = 2\n",
    "    for c in range(N_COLS):\n",
    "        for d in range(N_COLS):\n",
    "            #if hsv(C[c], j) > hsv(C[d], j):\n",
    "            if hsv(C[c], j) > hsv(C[d], j):\n",
    "                tmp = C[c].copy()\n",
    "                C[c] = C[d].copy()\n",
    "                C[d] = tmp.copy()\n",
    "\n",
    "    for i, c in enumerate(C):\n",
    "        #P[100*j:100*(1+j),100*i:100*(1+i),:] = c\n",
    "        P[:,100*i:100*(1+i),:] = c\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"dataset/upper_body/images/denim_denim-shirts/12141279ui_0_r.jpg\")\n",
    "img = cv2.imread(\"dataset/upper_body/images/knitwear_track-tops/46614975wd_0_d.jpg\")\n",
    "img = cv2.imread(\"dataset/upper_body/images/knitwear_track-tops/46662850ev_0_d.jpg\")\n",
    "C = pantone(img)\n",
    "cv2.imshow(\"1\",C)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        # num_workers=config.NUM_WORKERS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/304 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.6022, 0.6772,  ..., 0.6552, 0.8752, 0.8161],\n",
      "        [0.6022, 0.0000, 0.4451,  ..., 0.3820, 0.5590, 0.5226],\n",
      "        [0.6772, 0.4451, 0.0000,  ..., 0.7587, 0.5251, 0.8110],\n",
      "        ...,\n",
      "        [0.6552, 0.3820, 0.7587,  ..., 0.0000, 0.4827, 0.7406],\n",
      "        [0.8752, 0.5590, 0.5251,  ..., 0.4827, 0.0000, 0.7751],\n",
      "        [0.8161, 0.5226, 0.8110,  ..., 0.7406, 0.7751, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_vec = None\n",
    "\n",
    "for h, img in tqdm(train_loader):\n",
    "    D =  (h[None,...]**2).sum(2) * (h[:,None,:]**2).sum(2)\n",
    "    sim = (h[None,...] * h[:,None,:]).sum(2) / np.where(D == 0, 1, D)**0.5 - np.eye(D.shape[0])\n",
    "    print(sim)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_idx = 3\n",
    "b_idx = sim[a_idx].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = img[a_idx]\n",
    "b = img[b_idx]\n",
    "\n",
    "cv2.imshow(\"a\", a.numpy())\n",
    "cv2.imshow(\"b\", b.numpy())\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(16):\n",
    "    i = sim[j].argmax()\n",
    "    #p1 = pantone(img[j])\n",
    "    #p2 = pantone(img[i])\n",
    "\n",
    "    #cv2.imshow(\"1\",p1)\n",
    "    #cv2.imshow(\"2\",p2)\n",
    "    cv2.imshow(\"1v\",img[j].numpy())\n",
    "    cv2.imshow(\"2v\",img[i].numpy())\n",
    "    K = cv2.waitKey()\n",
    "    if K == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if K == 100:\n",
    "        print(\"FUNZIONE\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 vs ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        # num_workers=config.NUM_WORKERS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [17:58<00:00,  3.55s/it]\n"
     ]
    }
   ],
   "source": [
    "all_vec = None\n",
    "\n",
    "for i, (h, img) in enumerate(tqdm(train_loader)):\n",
    "    if all_vec is None:\n",
    "        all_vec = h.clone()\n",
    "    else:\n",
    "        all_vec = torch.cat([all_vec,h],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_vec.numpy())\n",
    "df.to_csv(\"dataset/vectorized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df.astype(pd.SparseDtype(\"float\", 0.0))\n",
    "sdf.to_csv(\"dataset/vectorized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense : 6.16 MB\n",
      "sparse : 1.27 MB\n"
     ]
    }
   ],
   "source": [
    "print('dense : {:0.2f} MB'.format(df.memory_usage().sum() / 1e6))\n",
    "print('sparse : {:0.2f} MB'.format(sdf.memory_usage().sum() / 1e6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19453, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/vectorized.csv\",index_col=0).values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2 #ispanico\n",
    "i = 1 #nordeuropeo\n",
    "i = 3000 #italiano abbronzato\n",
    "i = 3 #euroasiatico\n",
    "i = 5 #bella palette\n",
    "i = 10 #centro america\n",
    "i = 300 #carnagione chiara\n",
    "i = 349 #afroamericano\n",
    "i = 971 #esteuropeo\n",
    "i = 1245 #nord africa\n",
    "i = 200 #afroamericano\n",
    "i = 500 #italiano medio\n",
    "item = df[i]\n",
    "item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = (df**2).sum(1) * (item**2).sum()\n",
    "sim = (df * item).sum(1) / D**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14172,  1614,  2717, ..., 16836, 16272,  7705], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx = sim.argsort()[::-1][1:]\n",
    "best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 2112, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train_dataset[i][1]\n",
    "\n",
    "for j in best_idx.tolist()[:10]:\n",
    "    img = np.concatenate([img, train_dataset[j][1]], 1)\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15ce8c5ab5f6ecfdc053f441697a5123a305bcbae066728b1d823115abe8612e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
